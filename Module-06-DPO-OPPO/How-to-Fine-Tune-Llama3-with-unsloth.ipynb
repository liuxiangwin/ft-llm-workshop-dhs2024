{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to FineTune Llama 3 with  SFTTrainer and  Unsloth\n",
    "Hello everyone, today we are going to show how we can Fine Tune Llama 3 with SFTTrainer and Unsloth\n",
    "First we are going to perform a simmple Fine Tunning by using SFTTrainer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 - Installation of Pytorch\n",
    "The first step is install pythorch v 2.2.1 with Cuda 12.1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /opt/app-root/lib64/python3.11/site-packages (24.3.1)\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "kfp 2.9.0 requires protobuf<5,>=4.21.1, but you have protobuf 3.20.3 which is incompatible.\n",
      "kfp-kubernetes 1.3.0 requires protobuf<5,>=4.21.1, but you have protobuf 3.20.3 which is incompatible.\n",
      "kfp-pipeline-spec 0.4.0 requires protobuf<5,>=4.21.1, but you have protobuf 3.20.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "unsloth-zoo 2024.11.8 requires protobuf<4.0.0, but you have protobuf 5.28.3 which is incompatible.\n",
      "kfp 2.9.0 requires protobuf<5,>=4.21.1, but you have protobuf 5.28.3 which is incompatible.\n",
      "kfp-kubernetes 1.3.0 requires protobuf<5,>=4.21.1, but you have protobuf 5.28.3 which is incompatible.\n",
      "kfp-pipeline-spec 0.4.0 requires protobuf<5,>=4.21.1, but you have protobuf 5.28.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install -q -U git+https://github.com/huggingface/transformers.git --quiet\n",
    "!pip install trl wandb --quiet\n",
    "!pip install \"unsloth[cu121-torch240] @ git+https://github.com/unslothai/unsloth.git\" --quiet\n",
    "!pip install --no-deps xformers trl peft accelerate bitsandbytes --quiet\n",
    "!pip install  --upgrade --quiet \\\n",
    "  \"datasets>=2.21.0\" \\\n",
    "  \"evaluate==0.4.1\" \\\n",
    "  \"pillow\" \\\n",
    "  \"hyperopt\" \\\n",
    "  \"optuna\" \\\n",
    "  \"protobuf>=4.21.1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 - Installation of Uslotch packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 - Analysis of our infrastructure\n",
    "In ordering to perform any training it is important to know our system in order to take the full advantage of the system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What is SFTTrainer?**\n",
    "\n",
    "`SFTTrainer` is a class from the `trl` library that implements the SFT algorithm. It is a specialized trainer class that is designed to work with the SFT method. The `SFTTrainer` class takes in a pre-trained model, a dataset, and a set of hyperparameters, and fine-tunes the model using the SFT algorithm.\n",
    "\n",
    "**What is the difference between SFTTrainer and Trainer?**\n",
    "\n",
    "The main difference between `SFTTrainer` and the `Trainer` class from the `transformers` library is the fine-tuning algorithm used. The `Trainer` class uses the standard fine-tuning algorithm, where all the model's weights are updated during training. In contrast, the `SFTTrainer` class uses the SFT algorithm, which only updates a small subset of the model's weights. This makes `SFTTrainer` more efficiend suitable for large language models.\n",
    "\n",
    "**Key differences between SFTTrainer and Trainer**\n",
    "\n",
    "Here is a table summarizing the key differences between `SFTTrainer` and `Trainer`:\n",
    "\n",
    "|  | SFTTrainer | Trainer |\n",
    "| --- | --- | --- |\n",
    "| Fine-tuning algorithm | Sparse Fine-Tuning (SFT) | Standard fine-tuning |\n",
    "| Weights updated | Only a small subset of weights | All weights |\n",
    "| Efficiency | More efficient for large models | Less efficient for large models |\n",
    "| Suitable for | Large language models | Small to medium-sized models |\n",
    "| Library | `trl` library | `transformers` library |\n",
    "\n",
    "Features\n",
    "\n",
    "| Feature | SFTTrainer | Trainer |\n",
    "| --- | --- | --- |\n",
    "| Complexity | Simple, lightweight | More comprehensive, feature-rich |\n",
    "| Customization | Limited options | Advanced customization options |\n",
    "| Ease of use | Easy to use, minimal code | More code required, steeper learning curve |\n",
    "| Integration | Standalone trainer | Part of Hugging Face Transformers library |\n",
    "| Use cases | Quick fine-tuning, prototyping | Large-scale training, complex models |\n",
    "\n",
    "Note that the `SFTTrainer` class is specifically designed for sparse fine-tuning, while the `Trainer` class is a more general-purpose trainer class that can be used for a variety of fine-tuning tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to FineTune with Unsloth\n",
    "Hello everyone, today we are going to show how we can Fine Tune Llama 3 with a Usloth package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5 -  Loading packages\n",
    "Once we have installed all the packages we load the packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n",
      "2.4.1+cu121\n",
      "12.1\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from huggingface_hub import notebook_login\n",
    "from transformers import TrainingArguments\n",
    "from trl import SFTTrainer\n",
    "from unsloth import FastLanguageModel\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)\n",
    "\n",
    "from huggingface_hub import login\n",
    "login(\n",
    "  token=\"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\", # ADD YOUR TOKEN HERE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6 -  Setup configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Model Configuration**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config={ \"model_config\": {\n",
    "    \"base_model\": \"meta-llama/Meta-Llama-3-8B-Instruct\",  # The base model\n",
    "    \"finetuned_model\": \"ruslanmv/Medical-Mind-Llama-3-8b-1M\",  # The finetuned model\n",
    "    \"finetuned_name\": \"Medical-Mind-Llama-3-8b-v1M\",\n",
    "    \"max_seq_length\": 2048,  # The maximum sequence length\n",
    "    \"dtype\": None,  # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
    "    \"load_in_4bit\": True,  # Load the model in 4-bit\n",
    "}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `base_model`: specifies the pre-trained model to use as the base model for fine-tuning.\n",
    "* `finetuned_model`: specifies the finetuned model to use for fine-tuning.\n",
    "* `finetuned_name`: specifies the name of the finetuned model.\n",
    "* `max_seq_length`: specifies the maximum sequence length that the model can process.\n",
    "* `dtype`: specifies the data type to use for the model's weights and activations. `None` means auto-detection, which will choose the most suitable data type based on the hardware.\n",
    "* `load_in_4bit`: specifies whether to load the model i 4-bit precision, which can reduce memory usage and improve performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LoRA Configuration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_config={\"lora_config\": {\n",
    "    \"r\": 16,  # The number of LoRA layers 8, 16, 32, 64\n",
    "    \"target_modules\": [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                      \"gate_proj\", \"up_proj\", \"down_proj\"],  # The target modules\n",
    "    \"lora_alpha\": 16,  # The alpha value for LoRA\n",
    "    \"lora_dropout\": 0,  # The dropout value for LoRA\n",
    "    \"bias\": \"none\",  # The bias for LoRA\n",
    "    \"use_gradient_checkpointing\": True,  # Use gradient checkpointing\n",
    "    \"use_rslora\": False,  # Use RSLora\n",
    "    \"use_dora\": False,  # Use DoRa\n",
    "    \"loftq_config\": None  # The LoFTQ configuration\n",
    "}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `r`: specifies the number of LoRA layers to use.\n",
    "* `target_modules`: specifies the modules to which LoRA should be applied.\n",
    "* `lora_alpha`: specifies the alpha value for LoRA, which controls the strength of the LoRA layers.\n",
    "* `lora_dropout`: specifies the dropout value for LoRA, which controls the random dropping of neurons during training.\n",
    "* `bias`: specifies the bias for LoRA, which can be set to \"none\" or a specific value.\n",
    "* `use_gradient_checkpointing`: specifies whether to use gradient checkpointing, which can reduce memory usage during training.\n",
    "* `use_rslora` and `use_dora`: specify whether to use RSLora and DoRa, respectively, which are variants of LoRA.\n",
    "* `loftq_config`: specifies the LoFTQ configuration, which is not used in this example.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training Configuration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_config={\"training_config\": {\n",
    "    \"per_device_train_batch_size\": 2,  # The batch size\n",
    "    \"gradient_accumulation_steps\": 4,  # The gradient accumulation steps\n",
    "    \"warmup_steps\": 5,  # The warmup steps\n",
    "    \"max_steps\": 0,  # The maximum steps (0 if the epochs are defined)\n",
    "    \"num_train_epochs\": 1,  # The number of training epochs\n",
    "    \"learning_rate\": 2e-4,  # The learning rate\n",
    "    \"fp16\": not torch.cuda.is_bf16_supported(),  # The fp16\n",
    "    \"bf16\": torch.cuda.is_bf16_supported(),  # The bf16\n",
    "    \"logging_steps\":  1,  # The logging steps\n",
    "    \"optim\": \"adamw_8bit\",  # The optimizer\n",
    "    \"weight_decay\": 0.0,  # The weight decay\n",
    "    \"lr_scheduler_type\": \"linear\",  # The learning rate scheduler\n",
    "    \"seed\": 42,  # The seed\n",
    "    \"output_dir\": \"outputs\",  # The output directory\n",
    "}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `per_device_train_batch_size`: specifies the batch size to use for training.\n",
    "* `gradient_accumulation_steps`: specifies the number of steps to accumulate gradients before updating the model.\n",
    "* `warmup_steps`: specifies the number of warmup steps to perform before starting training.\n",
    "* `max_steps`: specifies the maximum number of steps to train for. If set to 0, the model will train for the specified number of epochs.\n",
    "* `num_train_epochs`: specifies the number of epochs to train for.\n",
    "* `learning_rate`: specifies the initial learning rate to use for training.\n",
    "* `fp16` and `bf16`: specify whether to use 16-bit floating-point precision (fp16) or 16-bit bfloat precision (bf16) for training.\n",
    "* `logging_steps`: specifies the number of steps to log training metrics.\n",
    "* `optim`: specifies the optimizer to use for training.\n",
    "* `weight_decay`: specifies the weight decay rate to use for regularization.\n",
    "* `lr_scheduler_type`: specifies the learning rate scheduler to use.\n",
    "* `seed`: specifies the random seed to use for training.\n",
    "* `output_dir`: specifies the output directory to save training results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hugging Face Username**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "hugging_face_username={\"hugging_face_username\": \"ruslanmv\"}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset={\"training_dataset\": {\n",
    "        \"name\": \"ruslanmv/ai-medical-dataset\", # The dataset name(huggingface/datasets)\n",
    "        \"split\": \"train\",  # The dataset split\n",
    "        \"input_fields\": [\"question\", \"context\"] ,# The input fields\n",
    "        \"input_field\": \"text\",# The input field\n",
    "    },\n",
    "                }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`training_dataset`**: This is the top-level key for the dataset configuration.\n",
    "\n",
    "**`name`**: This specifies the name of the dataset. In this case, it's `ruslanmv/ai-medical-dataset`, which is a dataset hosted on the Hugging Face Hub. The format is `username/dataset_name`.\n",
    "\n",
    "**`split`**: This specifies the split of the dataset to use for training. In this case, it's set to `\"train\"`, which means the model will be trained on the training split of the dataset.\n",
    "\n",
    "**`input_fields`**: This specifies the input fields of the dataset that will be used for trainine, it's a list containing two fields: `\"question\"` and `\"context\"`. These fields are likely to be the input features of the dataset.\n",
    "\n",
    "**`input_field`**: This specifies the primary input field of the dataset. In this case, it's set to `\"text\"`. This field is likely to be the text input that the model will process.\n",
    "\n",
    "Here's an example of what this dataset might look like:\n",
    "\n",
    "| question | context | text |\n",
    "| --- | --- | --- |\n",
    "| How does COVID-19 spread? | COVID-19 is a respiratory disease... | The COVID-19 is.. |\n",
    "| ... | ... | ... |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {}\n",
    "config.update(hugging_face_username)\n",
    "config.update(model_config)\n",
    "config.update(lora_config)\n",
    "config.update(training_config)\n",
    "config.update(training_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def save_config_to_json(config, file_path):\n",
    "    with open(file_path, 'w') as f:\n",
    "        json.dump(config, f, indent=4)\n",
    "file_path = \"original_config.json\"\n",
    "save_config_to_json(config, file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2024.11.10: Fast Llama patching. Transformers:4.47.0.dev0.\n",
      "   \\\\   /|    GPU: NVIDIA A10G. Max memory: 21.975 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.4.1+cu121. CUDA: 8.6. CUDA Toolkit: 12.1. Triton: 3.0.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.28.post1. FA2 = False]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    }
   ],
   "source": [
    "# Loading the model and the tokenizer for the model\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=config[\"model_config\"].get(\"base_model\"),\n",
    "    max_seq_length=config[\"model_config\"].get(\"max_seq_length\"),\n",
    "    dtype=config[\"model_config\"].get(\"dtype\"),\n",
    "    load_in_4bit=config[\"model_config\"].get(\"load_in_4bit\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2024.11.10 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "# Setup for QLoRA/LoRA peft of the base model\n",
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = config.get(\"lora_config\").get(\"r\"),\n",
    "    target_modules = config.get(\"lora_config\").get(\"target_modules\"),\n",
    "    lora_alpha = config.get(\"lora_config\").get(\"lora_alpha\"),\n",
    "    lora_dropout = config.get(\"lora_config\").get(\"lora_dropout\"),\n",
    "    bias = config.get(\"lora_config\").get(\"bias\"),\n",
    "    use_gradient_checkpointing = config.get(\"lora_config\").get(\"use_gradient_checkpointing\"),\n",
    "    random_state = 42,\n",
    "    use_rslora = config.get(\"lora_config\").get(\"use_rslora\"),\n",
    "    use_dora = config.get(\"lora_config\").get(\"use_dora\"),\n",
    "    loftq_config = config.get(\"lora_config\").get(\"loftq_config\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from transformers import AutoModelForCausalLM, BitsAndBytesConfig, AutoTokenizer\n",
    "#tokenizer = AutoTokenizer.from_pretrained(config.get(\"model_config\").get(\"base_model\"))\n",
    "tokenizer.add_eos_token = True\n",
    "tokenizer.pad_token_id = 0\n",
    "tokenizer.padding_side = \"left\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset exists!\n"
     ]
    }
   ],
   "source": [
    "is_test=True\n",
    "import datasets\n",
    "import os\n",
    "dataset_path = \"train_dataset\"\n",
    "if os.path.exists(dataset_path):\n",
    "    print(\"Dataset exists!\")\n",
    "    train_dataset = datasets.load_from_disk(\"train_dataset\")\n",
    "else:\n",
    "    print(\"Dataset does not exist.\")\n",
    "    # Loading the training dataset\n",
    "    train_dataset = load_dataset(config.get(\"training_dataset\").get(\"name\"), split = config.get(\"training_dataset\").get(\"split\"))    \n",
    "    \n",
    "    if is_test:\n",
    "        # Select the first 1M rows of the dataset\n",
    "        train_dataset = train_dataset.select(range(100))\n",
    "        \n",
    "    medical_prompt = \"\"\"You are an AI Medical Assistant Chatbot, trained to answer medical questions. Below is an instruction that describes a task, paired with an response context. Write a response that appropriately completes the request.\n",
    "    ### Instruction:\n",
    "    {}\n",
    "\n",
    "    ### Response:\n",
    "    {}\"\"\"\n",
    "    EOS_TOKEN = tokenizer.eos_token # Must add EOS_TOKEN\n",
    "    def formatting_prompts_func(examples):\n",
    "        instructions = examples[\"question\"]\n",
    "        outputs      = examples[\"context\"]\n",
    "        texts = []\n",
    "        for instruction, output in zip(instructions,  outputs):\n",
    "            # Must add EOS_TOKEN, otherwise your generation will go on forever!\n",
    "            text = medical_prompt.format(instruction,  output) + EOS_TOKEN\n",
    "            texts.append(text)\n",
    "        return { \"text\" : texts, }\n",
    "    pass\n",
    "    train_dataset= train_dataset.map(formatting_prompts_func, batched = True,)\n",
    "    train_dataset['text'][1]    \n",
    "    import datasets\n",
    "    # assume 'test_dataset' is a Dataset object\n",
    "    train_dataset.save_to_disk(\"train_dataset\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'context', 'text'],\n",
       "    num_rows: 100\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_multiple=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No DataParallel \n"
     ]
    }
   ],
   "source": [
    "if is_multiple:\n",
    "    # Set up GPU acceleration\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        print(\"Multiple GPUs enabled\")\n",
    "        devices = [f\"cuda:{i}\" for i in range(torch.cuda.device_count())]\n",
    "        model_parallel = torch.nn.DataParallel(model, device_ids= devices ) #[0, 1]\n",
    "        # Access the original model from the DataParallel object\n",
    "        model = model_parallel.module\n",
    "    else:\n",
    "        print(\"No DataParallel \")\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        model.to(device)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "836f3fb32c2a46db95397ad130f0768b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=2):   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Setting up the trainer for the model\n",
    "trainer = SFTTrainer(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    train_dataset = train_dataset,\n",
    "    dataset_text_field = config.get(\"training_dataset\").get(\"input_field\"),\n",
    "    max_seq_length = config.get(\"model_config\").get(\"max_seq_length\"),\n",
    "    dataset_num_proc = 2,\n",
    "    packing = False,\n",
    "    args = TrainingArguments(\n",
    "        per_device_train_batch_size = config.get(\"training_config\").get(\"per_device_train_batch_size\"),\n",
    "        gradient_accumulation_steps = config.get(\"training_config\").get(\"gradient_accumulation_steps\"),\n",
    "        warmup_steps = config.get(\"training_config\").get(\"warmup_steps\"),\n",
    "        max_steps = config.get(\"training_config\").get(\"max_steps\"),\n",
    "        num_train_epochs= config.get(\"training_config\").get(\"num_train_epochs\"),\n",
    "        learning_rate = config.get(\"training_config\").get(\"learning_rate\"),\n",
    "        fp16 = config.get(\"training_config\").get(\"fp16\"),\n",
    "        bf16 = config.get(\"training_config\").get(\"bf16\"),\n",
    "        logging_steps = config.get(\"training_config\").get(\"logging_steps\"),\n",
    "        optim = config.get(\"training_config\").get(\"optim\"),\n",
    "        weight_decay = config.get(\"training_config\").get(\"weight_decay\"),\n",
    "        lr_scheduler_type = config.get(\"training_config\").get(\"lr_scheduler_type\"),\n",
    "        seed = 42,\n",
    "        output_dir = config.get(\"training_config\").get(\"output_dir\"),\n",
    "        \n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reserved Memory: 5.61GB\n",
      "Max Memory: 21.98GB\n"
     ]
    }
   ],
   "source": [
    "# Memory statistics before training\n",
    "gpu_statistics = torch.cuda.get_device_properties(0)\n",
    "reserved_memory = round(torch.cuda.max_memory_reserved() / 1024**3, 2)\n",
    "max_memory = round(gpu_statistics.total_memory / 1024**3, 2)\n",
    "print(f\"Reserved Memory: {reserved_memory}GB\")\n",
    "print(f\"Max Memory: {max_memory}GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "Q-g-4RvNXkyD"
   },
   "outputs": [],
   "source": [
    "##  [ 1038/2651250 53:49 < 2295:10:28, 0.32 it/s, Epoch 0.00/1] old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
      "   \\\\   /|    Num examples = 100 | Num Epochs = 1\n",
      "O^O/ \\_/ \\    Batch size per device = 2 | Gradient Accumulation steps = 4\n",
      "\\        /    Total batch size = 8 | Total steps = 12\n",
      " \"-____-\"     Number of trainable parameters = 41,943,040\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mliuxiangwin\u001b[0m (\u001b[33mliuxiangwin-free\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/opt/app-root/src/ft-llm-workshop-dhs2024/Module-06-DPO-OPPO/wandb/run-20241127_050754-011ckn5g</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/liuxiangwin-free/huggingface/runs/011ckn5g' target=\"_blank\">outputs</a></strong> to <a href='https://wandb.ai/liuxiangwin-free/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/liuxiangwin-free/huggingface' target=\"_blank\">https://wandb.ai/liuxiangwin-free/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/liuxiangwin-free/huggingface/runs/011ckn5g' target=\"_blank\">https://wandb.ai/liuxiangwin-free/huggingface/runs/011ckn5g</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/app-root/lib64/python3.11/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
      "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12/12 00:37, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.115300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.827700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.457200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.762900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.366200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2.300200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2.096300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2.046700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>2.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.802600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>2.038700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.689900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Training the model\n",
    "trainer_stats = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YQFEr64koXp1",
    "outputId": "2e1b3775-1f5d-4b8e-a0ef-32266cb7fa2a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Memory: 7.2GB (32.76%)\n",
      "Used Memory for training(fine-tuning) LoRA: 1.59GB (7.23%)\n"
     ]
    }
   ],
   "source": [
    "# Memory statistics after training\n",
    "used_memory = round(torch.cuda.max_memory_allocated() / 1024**3, 2)\n",
    "used_memory_lora = round(used_memory - reserved_memory, 2)\n",
    "used_memory_persentage = round((used_memory / max_memory) * 100, 2)\n",
    "used_memory_lora_persentage = round((used_memory_lora / max_memory) * 100, 2)\n",
    "print(f\"Used Memory: {used_memory}GB ({used_memory_persentage}%)\")\n",
    "print(f\"Used Memory for training(fine-tuning) LoRA: {used_memory_lora}GB ({used_memory_lora_persentage}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model=config.get(\"model_config\").get(\"finetuned_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ruslanmv/Medical-Mind-Llama-3-8b-1M'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "1YJB4bZyoXp1"
   },
   "outputs": [],
   "source": [
    "# Saving the trainer stats\n",
    "with open(\"trainer_stats.json\", \"w\") as f:\n",
    "    json.dump(trainer_stats, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save and push the adapter to HF\n",
    "import os\n",
    "current_directory = os.getcwd()\n",
    "# New model name\n",
    "new_model = config.get(\"model_config\").get(\"finetuned_name\") #\"Medical-Mind-Llama-3-8b\"\n",
    "# Save the fine-tuned model\n",
    "save_path = os.path.join(current_directory, \"models\", new_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/opt/app-root/src/ft-llm-workshop-dhs2024/Module-06-DPO-OPPO/models/Medical-Mind-Llama-3-8b-v1M/tokenizer_config.json',\n",
       " '/opt/app-root/src/ft-llm-workshop-dhs2024/Module-06-DPO-OPPO/models/Medical-Mind-Llama-3-8b-v1M/special_tokens_map.json',\n",
       " '/opt/app-root/src/ft-llm-workshop-dhs2024/Module-06-DPO-OPPO/models/Medical-Mind-Llama-3-8b-v1M/tokenizer.json')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#os.makedirs(save_path, exist_ok=True)  # Create directory if it doesn't exist\n",
    "#trainer.model.save_pretrained(save_path)\n",
    "tokenizer.save_pretrained(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method unsloth_save_pretrained_merged in module unsloth.save:\n",
      "\n",
      "unsloth_save_pretrained_merged(save_directory: Union[str, os.PathLike], tokenizer=None, save_method: str = 'merged_16bit', push_to_hub: bool = False, token: Union[str, bool, NoneType] = None, is_main_process: bool = True, state_dict: Optional[dict] = None, save_function: Callable = <function save at 0x7f57c1a86fc0>, max_shard_size: Union[int, str] = '5GB', safe_serialization: bool = True, variant: Optional[str] = None, save_peft_format: bool = True, tags: List[str] = None, temporary_location: str = '_unsloth_temporary_saved_buffers', maximum_memory_usage: float = 0.75) method of peft.peft_model.PeftModelForCausalLM instance\n",
      "    Same as .save_pretrained(...) except 4bit weights are auto\n",
      "    converted to float16 with as few overhead as possible.\n",
      "    \n",
      "    Choose for `save_method` to be either:\n",
      "    1. `16bit`: Merge LoRA into float16 weights. Useful for GGUF / llama.cpp.\n",
      "    2.  `4bit`: Merge LoRA into int4 weights. Useful for DPO / HF inference.\n",
      "    3.  `lora`: Save LoRA adapters with no merging. Useful for HF inference.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(model.save_pretrained_merged)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To save the final model as LoRA adapters, either use Huggingface's push_to_hub for an online save or save_pretrained for a local save.\n",
    "\n",
    "[NOTE] This ONLY saves the LoRA adapters, and not the full model. To save to 16bit or GGUF, scroll down!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model to the created directory\n",
    "# `lora`: Save LoRA adapters with no merging. Useful for HF inference.\n",
    "#model.save_pretrained(save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the model using merged_16bit(float16), \n",
    "#`16bit`: Merge LoRA into float16 weights. Useful for GGUF / llama.cpp.\n",
    "#model.save_pretrained_merged(save_path, tokenizer, save_method = \"merged_16bit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Merging 4bit and LoRA weights to 4bit...\n",
      "This might take 5 minutes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/app-root/lib64/python3.11/site-packages/peft/tuners/lora/bnb.py:336: UserWarning: Merge lora module to 4-bit linear may get different generations due to rounding errors.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "Unsloth: Saving tokenizer... Done.\n",
      "Unsloth: Saving model... This might take 10 minutes for Llama-7b... Done.\n"
     ]
    }
   ],
   "source": [
    "# `4bit`: Merge LoRA into int4 weights. Useful for DPO / HF inference.\n",
    "model.save_pretrained_merged(save_path, tokenizer, save_method = \"merged_4bit_forced\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/opt/app-root/src/ft-llm-workshop-dhs2024/Module-06-DPO-OPPO/models/Medical-Mind-Llama-3-8b-v1M'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in the directory:\n",
      "model-00002-of-00002.safetensors\n",
      "model-00001-of-00002.safetensors\n",
      "tokenizer.json\n",
      "model.safetensors.index.json\n",
      "special_tokens_map.json\n",
      "generation_config.json\n",
      "tokenizer_config.json\n",
      "config.json\n"
     ]
    }
   ],
   "source": [
    "# Get the list of files in the directory\n",
    "files_in_model_dir = os.listdir(save_path)\n",
    "# Print the list of files\n",
    "print(\"Files in the directory:\")\n",
    "for file in files_in_model_dir:\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from huggingface_hub import HfApi\n",
    "def upload_folder(folder_path, repository_name, path_in_repo):\n",
    "    api = HfApi()\n",
    "    \n",
    "    # Check if the repository exists, if not, create it\n",
    "    repo_exists = api.repo_exists(repository_name)\n",
    "    if not repo_exists:\n",
    "        api.create_repo(repository_name)\n",
    "        print(f\"Repository '{repository_name}' created on Hugging Face Hub.\")\n",
    "\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(root, file)\n",
    "            relative_path = os.path.relpath(file_path, folder_path)\n",
    "            repo_path = os.path.join(path_in_repo, relative_path)\n",
    "            api.upload_file(path_or_fileobj=file_path, repo_id=repository_name, path_in_repo=repo_path)\n",
    "            print(f\"{repo_path} uploaded to {repository_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the repository name and path in the repository\n",
    "repository_name = \"Liu-Xiang/\"+new_model\n",
    "path_in_repo = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Liu-Xiang/Medical-Mind-Llama-3-8b-v1M'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repository_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model-00002-of-00002.safetensors uploaded to Liu-Xiang/Medical-Mind-Llama-3-8b-v1M\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e31589906bb945acbbf625c3a7d6a757",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/4.65G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model-00001-of-00002.safetensors uploaded to Liu-Xiang/Medical-Mind-Llama-3-8b-v1M\n",
      "tokenizer.json uploaded to Liu-Xiang/Medical-Mind-Llama-3-8b-v1M\n",
      "model.safetensors.index.json uploaded to Liu-Xiang/Medical-Mind-Llama-3-8b-v1M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n",
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "special_tokens_map.json uploaded to Liu-Xiang/Medical-Mind-Llama-3-8b-v1M\n",
      "generation_config.json uploaded to Liu-Xiang/Medical-Mind-Llama-3-8b-v1M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n",
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizer_config.json uploaded to Liu-Xiang/Medical-Mind-Llama-3-8b-v1M\n",
      "config.json uploaded to Liu-Xiang/Medical-Mind-Llama-3-8b-v1M\n"
     ]
    }
   ],
   "source": [
    "# Upload the folder and its contents to the repository\n",
    "upload_folder(save_path, repository_name, path_in_repo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#help(model.push_to_hub_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_path='/home/wsuser/work/models/Medical-Mind-Llama-3-8b'\n",
    "#repo_id='ruslanmv/Medical-Mind-Llama-3-8b'\n",
    "#commit_message=\"Uploading Model\"\n",
    "#model.push_to_hub_merged(repo_id, tokenizer, save_method = \"merged_16bit\",commit_message=commit_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.push_to_hub_merged(config.get(\"model_config\").get(\"finetuned_model\"), tokenizer, save_method = \"merged_4bit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save_pretrained_gguf(config.get(\"model_config\").get(\"finetuned_model\"), tokenizer)\n",
    "#model.push_to_hub_gguf(config.get(\"model_config\").get(\"finetuned_model\"), tokenizer,repository_private=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save_pretrained_gguf(config.get(\"model_config\").get(\"finetuned_model\"), tokenizer, quantization_method = \"q4_k_m\")\n",
    "#model.push_to_hub_gguf(config.get(\"model_config\").get(\"finetuned_model\"), tokenizer, quantization_method = \"q4_k_m\",private=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_inference=False\n",
    "if is_inference:\n",
    "    from unsloth import FastLanguageModel\n",
    "    import torch\n",
    "    max_seq_length = 2048 # Choose any! We auto support RoPE Scaling internally!\n",
    "    dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
    "    load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n",
    "    model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "        model_name = \"ruslanmv/Medical-Mind-Llama-3-8b-1M\",\n",
    "        max_seq_length = max_seq_length,\n",
    "        dtype = dtype,\n",
    "        load_in_4bit = load_in_4bit,\n",
    "    )\n",
    "    # Using FastLanguageModel for fast inference\n",
    "    FastLanguageModel.for_inference(model)\n",
    "    question=\"This is the question: What was the main cause of the inflammatory CD4+ T cells?\"\n",
    "    prompt=f\"<|start_header_id|>system<|end_header_id|> You are a Medical AI chatbot assistant .<|eot_id|><|start_header_id|> user <|end_header_id|>{question}<|eot_id|>\"\n",
    "    # Tokenizing the input and generating the output\n",
    "    inputs = tokenizer([prompt], return_tensors = \"pt\").to(\"cuda\")\n",
    "    outputs = model.generate(**inputs, max_new_tokens = 256, use_cache = True)\n",
    "    answer = tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]  # Get the first element from the batch\n",
    "\n",
    "    # Split the answer at the first line break, assuming system intro and question are on separate lines\n",
    "    answer_parts = answer.split(\"\\n\", 1)\n",
    "\n",
    "    # If there are multiple parts, consider the second part as the answer\n",
    "    if len(answer_parts) > 1:\n",
    "      answer = answer_parts[1].strip()  # Remove leading/trailing whitespaces\n",
    "    else:\n",
    "      answer = \"\"  # If no split possible, set answer to empty string\n",
    "\n",
    "    print(f\"Answer: {answer}\")    \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter search\n",
    "**Step 1: Define the Hyperparameter Search Space**\n",
    "We need to define the search space for the hyperparameters we want to tune. For example, let's say we want to tune the following hyperparameters:\n",
    "\n",
    "* `learning_rate`\n",
    "* `per_device_train_batch_size`\n",
    "* `gradient_accumulation_steps`\n",
    "* `warmup_steps`\n",
    "* `num_train_epochs`\n",
    "* `lora_alpha`\n",
    "* `lora_dropout`\n",
    "\n",
    "We can define the search space as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hyperopt\n",
    "from hyperopt import hp\n",
    "from hyperopt import Trials\n",
    "from hyperopt import fmin, tpe, Trials\n",
    "# Define the search space for hyperparameters\n",
    "space = {\n",
    "  'learning_rate': hp.loguniform('learning_rate', -5, -1),  # Learning rate in log scale\n",
    "  #'lora_alpha': hp.quniform('lora_alpha', 1, 32, 1),  # LoRA alpha with quantized steps\n",
    "  #'lora_dropout': hp.uniform('lora_dropout', 0, 0.5),  # LoRA dropout rate\n",
    "\n",
    "  'per_device_train_batch_size': hp.quniform('per_device_train_batch_size', 2, 16, q=1),  \n",
    "  'gradient_accumulation_steps': hp.quniform('gradient_accumulation_steps', 1, 8, 1),  # Added for exploration\n",
    "  # Uncomment these if you want to tune other hyperparameters\n",
    "  # 'warmup_steps': hp.quniform('warmup_steps', 0, 1000, 1),\n",
    "  # 'num_train_epochs': hp.quniform('num_train_epochs', 1, 5, 1),    \n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2. Define the Objective Function**\n",
    "\n",
    "The objective function is a function that takes in the hyperparameters, sets them in the `config` dictionary, trains the model, and returns the loss or metric to minimize. We need to modify the previous fine-tuning code to define the objective function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "  # Set hyperparameters in the config dictionary (assuming it's defined elsewhere)\n",
    "  config['training_config']['learning_rate'] = params['learning_rate']\n",
    " # config['lora_config']['lora_alpha'] = params['lora_alpha']\n",
    " # config['lora_config']['lora_dropout'] = params['lora_dropout']   \n",
    "  config['training_config']['per_device_train_batch_size'] = params['per_device_train_batch_size']\n",
    "  config['training_config']['gradient_accumulation_steps'] = params['gradient_accumulation_steps']\n",
    "  # ... Set other hyperparameters from params dictionary ...   \n",
    "  #config['training_config']['warmup_steps'] = params['warmup_steps']\n",
    "  #config['training_config']['num_train_epochs'] = params['num_train_epochs']\n",
    "\n",
    "  # Load the model and tokenizer (assuming these are defined elsewhere)\n",
    "  try:\n",
    "      model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "          model_name=config.get(\"model_config\").get(\"base_model\"),\n",
    "          max_seq_length=config.get(\"model_config\").get(\"max_seq_length\"),\n",
    "          dtype=config.get(\"model_config\").get(\"dtype\"),\n",
    "          load_in_4bit=config.get(\"model_config\").get(\"load_in_4bit\"),\n",
    "      )\n",
    "  except Exception as e:\n",
    "      print(f\"Error loading model and tokenizer: {e}\")\n",
    "      return float(\"inf\")  # Return high value for errors\n",
    "\n",
    "  # Setup LoRA for the model (assuming FastLanguageModel supports LoRA)\n",
    "  try:\n",
    "      model = FastLanguageModel.get_peft_model(\n",
    "          model,\n",
    "          r=config.get(\"lora_config\").get(\"r\"),\n",
    "          target_modules=config.get(\"lora_config\").get(\"target_modules\"),\n",
    "          lora_alpha=params['lora_alpha'],\n",
    "          lora_dropout=params['lora_dropout'],\n",
    "          bias=config.get(\"lora_config\").get(\"bias\"),\n",
    "          use_gradient_checkpointing=config.get(\"lora_config\").get(\"use_gradient_checkpointing\"),\n",
    "          random_state=42,\n",
    "          use_rslora=config.get(\"lora_config\").get(\"use_rslora\"),\n",
    "          use_dora=config.get(\"lora_config\").get(\"use_dora\"),\n",
    "          loftq_config=config.get(\"lora_config\").get(\"loftq_config\")\n",
    "      )\n",
    "  except Exception as e:\n",
    "      print(f\"Error setting up LoRA: {e}\")\n",
    "      return float(\"inf\")  # Return high value for errors\n",
    "  # Train the model on the test dataset (assuming SFTTrainer and training arguments are defined)\n",
    "  try:\n",
    "      trainer = SFTTrainer(\n",
    "          model=model,\n",
    "          tokenizer=tokenizer,\n",
    "          train_dataset=train_dataset,\n",
    "          dataset_text_field=config.get(\"training_dataset\").get(\"input_field\"),\n",
    "          max_seq_length=config.get(\"model_config\").get(\"max_seq_length\"),\n",
    "          dataset_num_proc=2,\n",
    "          packing=False,\n",
    "          args=TrainingArguments(\n",
    "              per_device_train_batch_size=int(params['per_device_train_batch_size']),\n",
    "              gradient_accumulation_steps=params['gradient_accumulation_steps'],\n",
    "              warmup_steps=params['warmup_steps'],\n",
    "              max_steps=config.get(\"training_config\").get(\"max_steps\"),\n",
    "              num_train_epochs=params['num_train_epochs'],\n",
    "              learning_rate=params['learning_rate'],\n",
    "              fp16=config.get(\"training_config\").get(\"fp16\"),\n",
    "              bf16=config.get(\"training_config\").get(\"bf16\"),\n",
    "              logging_steps=config.get(\"training_config\").get(\"logging_steps\"),\n",
    "              optim=config.get(\"training_config\").get(\"optim\"),\n",
    "              weight_decay=config.get(\"training_config\").get(\"weight_decay\"),\n",
    "              lr_scheduler_type=config.get(\"training_config\").get(\"lr_scheduler_type\"),\n",
    "              seed=42,\n",
    "              output_dir=config.get(\"training_config\").get(\"output_dir\")\n",
    "          )\n",
    "      )\n",
    "      trainer_stats = trainer.train()\n",
    "      return trainer_stats.loss  # Assuming loss is the metric to minimize\n",
    "  except Exception as e:\n",
    "      print(f\"Error during training: {e}\")\n",
    "      return float(\"inf\")  # Return high value for failed trials\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3: Perform Hyperparameter Search**\n",
    "\n",
    "Now that we have defined the objective function, we can perform the hyperparameter search using Hyperopt's `fmin` function. We need to specify the objective function, the search space, and the maximum number of evaluations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2024.11.10: Fast Llama patching. Transformers:4.47.0.dev0.\n",
      "   \\\\   /|    GPU: NVIDIA A10G. Max memory: 21.975 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.4.1+cu121. CUDA: 8.6. CUDA Toolkit: 12.1. Triton: 3.0.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.28.post1. FA2 = False]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
      "Error setting up LoRA: 'lora_alpha'                  \n",
      "==((====))==  Unsloth 2024.11.10: Fast Llama patching. Transformers:4.47.0.dev0.\n",
      "   \\\\   /|    GPU: NVIDIA A10G. Max memory: 21.975 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.4.1+cu121. CUDA: 8.6. CUDA Toolkit: 12.1. Triton: 3.0.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.28.post1. FA2 = False]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
      "Error setting up LoRA: 'lora_alpha'                             \n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:12<00:00,  6.13s/trial, best loss: inf]\n",
      "Best Hyperparameters: {'gradient_accumulation_steps': 5.0, 'learning_rate': 0.2871033280321722, 'per_device_train_batch_size': 5.0}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create a Trials object to track hyperparameter evaluations\n",
    "trials = Trials()\n",
    "# Run hyperparameter optimization using TPE algorithm\n",
    "best = fmin(objective, space, algo=tpe.suggest, trials=trials, max_evals=2)\n",
    "# Print the best hyperparameters found during optimization\n",
    "print(\"Best Hyperparameters:\", best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory cleared!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import gc\n",
    "def reset_gpu_memory():\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    print(\"GPU memory cleared!\")\n",
    "# Example usage:\n",
    "reset_gpu_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full code version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2024.11.10: Fast Llama patching. Transformers:4.47.0.dev0.\n",
      "   \\\\   /|    GPU: NVIDIA A10G. Max memory: 21.975 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.4.1+cu121. CUDA: 8.6. CUDA Toolkit: 12.1. Triton: 3.0.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.28.post1. FA2 = False]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
      "  0%|          | 0/2 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "275b81bbfd5241498efbbc686c06094c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=2):   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
      "   \\\\   /|    Num examples = 100 | Num Epochs = 1\n",
      "O^O/ \\_/ \\    Batch size per device = 7 | Gradient Accumulation steps = 4.0\n",
      "\\        /    Total batch size = 28.0 | Total steps = 3\n",
      " \"-____-\"     Number of trainable parameters = 41,943,040\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during training: 'float' object cannot be interpreted as an integer\n",
      "==((====))==  Unsloth 2024.11.10: Fast Llama patching. Transformers:4.47.0.dev0.\n",
      "   \\\\   /|    GPU: NVIDIA A10G. Max memory: 21.975 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.4.1+cu121. CUDA: 8.6. CUDA Toolkit: 12.1. Triton: 3.0.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.28.post1. FA2 = False]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:12<00:12, 12.06s/trial, best loss: inf]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
      "   \\\\   /|    Num examples = 100 | Num Epochs = 1\n",
      "O^O/ \\_/ \\    Batch size per device = 7 | Gradient Accumulation steps = 6.0\n",
      "\\        /    Total batch size = 42.0 | Total steps = 2\n",
      " \"-____-\"     Number of trainable parameters = 41,943,040\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during training: 'float' object cannot be interpreted as an integer\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:23<00:00, 11.58s/trial, best loss: inf]\n",
      "Best Hyperparameters: {'gradient_accumulation_steps': 4.0, 'learning_rate': 0.008165034156541413, 'per_device_train_batch_size': 7.0}\n"
     ]
    }
   ],
   "source": [
    "####  Fixed Version\n",
    "import hyperopt\n",
    "from hyperopt import hp\n",
    "from hyperopt import Trials\n",
    "from hyperopt import fmin, tpe, Trials\n",
    "# Define the search space for hyperparameters\n",
    "space = {\n",
    "  'learning_rate'              : hp.loguniform('learning_rate', -5, -1),  # Learning rate in log scale\n",
    "  'per_device_train_batch_size': hp.quniform('per_device_train_batch_size', 2, 16, 1),   \n",
    "  'gradient_accumulation_steps': hp.quniform('gradient_accumulation_steps', 1, 8, 1), \n",
    "  # Uncomment these if you want to tune them\n",
    "  #'lora_alpha'                : hp.quniform('lora_alpha', 1, 32, 1),  # LoRA alpha with quantized steps\n",
    "  #'lora_dropout'              : hp.uniform('lora_dropout', 0, 0.5),  # LoRA dropout rate\n",
    "  # 'warmup_steps'             : hp.quniform('warmup_steps', 0, 1000, 1),\n",
    "  # 'num_train_epochs'         : hp.quniform('num_train_epochs', 1, 5, 1),\n",
    "}\n",
    "def objective(params):\n",
    "    # Set hyperparameters in the config dictionary (assuming it's defined elsewhere)\n",
    "    config['training_config']['learning_rate']=params['learning_rate']\n",
    "    config['training_config']['per_device_train_batch_size'] = params['per_device_train_batch_size']\n",
    "    config['training_config']['gradient_accumulation_steps'] = params['gradient_accumulation_steps']    \n",
    "    # config['lora_config']['lora_alpha'] = params['lora_alpha']\n",
    "    # config['lora_config']['lora_dropout'] = params['lora_dropout']\n",
    "    # ... Set other hyperparameters from params dictionary ...\n",
    "    #config['training_config']['warmup_steps'] = params['warmup_steps']\n",
    "    #config['training_config']['num_train_epochs'] = params['num_train_epochs']\n",
    "    # Load the model and tokenizer (assuming these are defined elsewhere)    \n",
    "    try:\n",
    "            model, tokenizer    = FastLanguageModel.from_pretrained(\n",
    "            model_name          = config.get(\"model_config\").get(\"base_model\"),\n",
    "            max_seq_length      = config.get(\"model_config\").get(\"max_seq_length\"),\n",
    "            dtype               = config.get(\"model_config\").get(\"dtype\"),\n",
    "            load_in_4bit        = config.get(\"model_config\").get(\"load_in_4bit\")\n",
    "            )\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading model and tokenizer: {e}\")\n",
    "        return float(\"inf\")  # Return high value for errors\n",
    "\n",
    "    # Setup LoRA for the model (assuming FastLanguageModel supports LoRA)\n",
    "    try:\n",
    "        model = FastLanguageModel.get_peft_model(\n",
    "        model,\n",
    "        r                            = config.get(\"lora_config\").get(\"r\"),\n",
    "        target_modules               = config.get(\"lora_config\").get(\"target_modules\"),\n",
    "        lora_alpha                   = config.get(\"lora_config\").get('lora_alpha'), #params['lora_alpha'],\n",
    "        lora_dropout                 = config.get(\"lora_config\").get('lora_dropout'),#params['lora_dropout'],\n",
    "        bias                         = config.get(\"lora_config\").get(\"bias\"),\n",
    "        use_gradient_checkpointing   = config.get(\"lora_config\").get(\"use_gradient_checkpointing\"),\n",
    "        random_state                 = 42,\n",
    "        use_rslora                   = config.get(\"lora_config\").get(\"use_rslora\"),\n",
    "        use_dora                     = config.get(\"lora_config\").get(\"use_dora\"),\n",
    "        loftq_config                 = config.get(\"lora_config\").get(\"loftq_config\")\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Error setting up LoRA: {e}\")\n",
    "        return float(\"inf\")  # Return high value for errors\n",
    "    # Train the model on the test dataset (assuming SFTTrainer and training arguments are defined)\n",
    "    try:\n",
    "        trainer = SFTTrainer(\n",
    "              model=model,\n",
    "              tokenizer            =  tokenizer,\n",
    "              train_dataset        = train_dataset,\n",
    "              dataset_text_field   = config.get(\"training_dataset\").get(\"input_field\"),\n",
    "              max_seq_length       = config.get(\"model_config\").get(\"max_seq_length\"),\n",
    "              dataset_num_proc     = 2,\n",
    "              packing              = False,\n",
    "              args=TrainingArguments(\n",
    "                  per_device_train_batch_size = int(params['per_device_train_batch_size']), #config.get(\"training_config\").get('per_device_train_batch_size'),\n",
    "                  gradient_accumulation_steps = params['gradient_accumulation_steps'], #config.get(\"training_config\").get('gradient_accumulation_steps'),\n",
    "                  warmup_steps                = config.get(\"training_config\").get('warmup_steps'),#params['warmup_steps'],\n",
    "                  max_steps                   = config.get(\"training_config\").get(\"max_steps\"),\n",
    "                  num_train_epochs            = config.get(\"training_config\").get('num_train_epochs'),#params['num_train_epochs'],\n",
    "                  learning_rate               = params['learning_rate'],\n",
    "                  fp16                        = config.get(\"training_config\").get(\"fp16\"),\n",
    "                  bf16                        = config.get(\"training_config\").get(\"bf16\"),\n",
    "                  logging_steps               = config.get(\"training_config\").get(\"logging_steps\"),\n",
    "                  optim                       = config.get(\"training_config\").get(\"optim\"),\n",
    "                  weight_decay                = config.get(\"training_config\").get(\"weight_decay\"),\n",
    "                  lr_scheduler_type           = config.get(\"training_config\").get(\"lr_scheduler_type\"),\n",
    "                  seed                        = 42,\n",
    "                  output_dir                  = config.get(\"training_config\").get(\"output_dir\")\n",
    "              )\n",
    "          )\n",
    "        trainer_stats = trainer.train()\n",
    "        return trainer_stats.loss  # Assuming loss is the metric to minimize\n",
    "    except Exception as e:\n",
    "        print(f\"Error during training: {e}\")\n",
    "        return float(\"inf\")  # Return high value for failed trials    \n",
    "# Create a Trials object to track hyperparameter evaluations\n",
    "trials = Trials()\n",
    "# Run hyperparameter optimization using TPE algorithm\n",
    "best = fmin(objective, space, algo=tpe.suggest, trials=trials, max_evals=2)\n",
    "# Print the best hyperparameters found during optimization\n",
    "print(\"Best Hyperparameters:\", best)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing Hyperparameters:\n",
    "\n",
    "*  **Batch Size**: Generally, increasing the batch size can improve training speed by utilizing hardware resources more efficiently. However, there's a limit beyond which performance degrades. You can tune the batch size within a reasonable range (e.g., 2, 4, 8, 16) to see its impact.\n",
    "\n",
    "* **Learning Rate**: A higher learning rate can accelerate training initially. But, a too high value can lead to unstable training and potentially slower convergence. Consider a range of learning rates (e.g., log-uniform distribution between 1e-5 and 1e-3) for exploration.\n",
    "\n",
    "* **Gradient Accumulation Steps**: This technique accumulates gradients over multiple batches before updating model weights. It can help reduce memory requirements but might slow down training per epoch. Experiment with different accumulation steps (e.g., 1, 2, 4) to find a balance.\n",
    "\n",
    "* **Optimizer Choice**: Some optimizers like Adam or SGD with momentum can be faster than others depending on the model and dataset. Explore different optimizers and their hyperparameters (e.g., momentum coefficient) to see if they lead to faster convergence.\n",
    "\n",
    "## Additional Considerations:\n",
    "\n",
    "Early Stopping: Implement early stopping to automatically terminate training if the validation loss doesn't improve for a certain number of epochs. This can save training time if the model starts overfitting.\n",
    "Warmup Steps: A gradual increase in the learning rate during the initial training phase (warmup steps) can improve stability and potentially accelerate convergence compared to a fixed learning rate from the beginning.\n",
    "\n",
    "\n",
    "* Experimentation and Profiling:\n",
    "\n",
    "The best hyperparameters for faster training depend on your specific model, dataset, and hardware. You'll need to experiment with different configurations using tools like Hyperopt to find the optimal settings.\n",
    "Consider using profiling tools to identify bottlenecks in your training pipeline. This can help you focus on optimizing specific parts of the training process that are most time-consuming.\n",
    "By analyzing these hyperparameters and implementing techniques like early stopping and warmup steps, you can potentially achieve faster fine-tuning while maintaining good model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 1  Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-27 05:12:11,220] A new study created in memory with name: no-name-34c4ae10-6a03-431c-92be-e443b4a0f7e5\n",
      "[I 2024-11-27 05:12:11,222] Trial 0 finished with value: inf and parameters: {'learning_rate': 0.00019489985443530553, 'per_device_train_batch_size': 8, 'gradient_accumulation_steps': 4, 'lora_alpha': 30}. Best is trial 0 with value: inf.\n",
      "[I 2024-11-27 05:12:11,224] Trial 1 finished with value: inf and parameters: {'learning_rate': 6.412343953715776e-05, 'per_device_train_batch_size': 7, 'gradient_accumulation_steps': 3, 'lora_alpha': 23}. Best is trial 0 with value: inf.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Trial: 0\n",
      "Best Hyperparameters (Likely Fastest): {'learning_rate': 0.00019489985443530553, 'per_device_train_batch_size': 8, 'gradient_accumulation_steps': 4, 'lora_alpha': 30}\n",
      "Best Training Time: inf seconds\n"
     ]
    }
   ],
   "source": [
    "from optuna import create_study, Trial\n",
    "import time  # Assuming you can use time.time() to measure training time\n",
    "\n",
    "# Define search space with additional hyperparameter\n",
    "search_space = {\n",
    "  \"learning_rate\": [1e-5, 5e-5, 1e-4, 2e-4],\n",
    "  \"per_device_train_batch_size\": [2, 4, 8],\n",
    "  \"lora_alpha\": [8, 16, 32],\n",
    "  \"gradient_accumulation_steps\": [1, 2, 4, 8],  # Added gradient accumulation steps\n",
    "}\n",
    "\n",
    "def objective(trial):\n",
    "  # Set hyperparameters based on trial values\n",
    "  config[\"training_config\"][\"learning_rate\"] = trial.suggest_float(\"learning_rate\", search_space[\"learning_rate\"][0], search_space[\"learning_rate\"][-1])\n",
    "  config[\"training_config\"][\"per_device_train_batch_size\"] = trial.suggest_int(\"per_device_train_batch_size\", search_space[\"per_device_train_batch_size\"][0], search_space[\"per_device_train_batch_size\"][-1])\n",
    "  config[\"training_config\"][\"gradient_accumulation_steps\"] = trial.suggest_int(\"gradient_accumulation_steps\", search_space[\"gradient_accumulation_steps\"][0], search_space[\"gradient_accumulation_steps\"][-1])\n",
    "  config[\"lora_config\"][\"lora_alpha\"] = trial.suggest_int(\"lora_alpha\", search_space[\"lora_alpha\"][0], search_space[\"lora_alpha\"][-1])\n",
    "\n",
    "  # Train the model with the current hyperparameters\n",
    "  start_time = time.time()\n",
    "  try:\n",
    "      trainer_stats = trainer_test.train()\n",
    "      training_time = time.time() - start_time\n",
    "      return training_time  # Minimize training time\n",
    "  except Exception as e:\n",
    "      return float(\"inf\")  # Assign a high value if training fails\n",
    "\n",
    "study = create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=2)  # Adjust the number of trials\n",
    "\n",
    "# Access the best trial and its hyperparameters after optimization\n",
    "best_trial = study.best_trial\n",
    "best_params = best_trial.params\n",
    "\n",
    "print(\"Best Trial:\", best_trial.number)\n",
    "print(\"Best Hyperparameters (Likely Fastest):\", best_params)\n",
    "print(\"Best Training Time:\", best_trial.value, \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0005f2d9fe1e4cc98ea58b0c2868b433": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_45c1d5b0df0e420a87f791dd4cf0e425",
      "max": 100,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9ed49f1a099846a3a65cd6608bafb0e4",
      "value": 100
     }
    },
    "0058ed544fed4272848a891a68b9adc0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "00eea4b0c6e44c62900ea8e7d919efe9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "02fc530028ea4d538b7f6b48463ae700": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "058b2b9959b84b6f9f5d3862ef53d029": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7807f312425b4f4d9249aa1ac77d7461",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_d8e7ea9552a84b8284b31d77090b54af",
      "value": "Mapâ€‡(num_proc=2):â€‡100%"
     }
    },
    "0f55ae30c2704632941cca4727c1c4f2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "11dc1dcf6b29471580c32c818fa41d88": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9344b22940c64654a82bb2ce06530e30",
       "IPY_MODEL_4f68a26f64e844c7be21cc180eb6c1a2",
       "IPY_MODEL_769b40273bab41af8eb66e494b613241"
      ],
      "layout": "IPY_MODEL_320c09781518483e82defa86c28316d1"
     }
    },
    "1634ba52355b4681a913039666926f85": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_eff94d2d010e4b4f93a6dfcb61103a52",
      "max": 18,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_da5cd094aaae45f4a0ca051ad5babd78",
      "value": 18
     }
    },
    "1850ab17bafd4a43b5ab5899d1875a40": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1a72b512e1374e67a858edf2844fc157": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_284192f01a924f87afd8b5087ca9af6c",
      "max": 18,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_273bf76f74bc4fb492ccb67d9e202f7b",
      "value": 18
     }
    },
    "217ca5cd404d4756a399fba3aa4fbc15": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8f88a5b04723482ea430679e504c65f9",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_8d153f070a8d4ad1b32996a9fd82beda",
      "value": "â€‡18/18â€‡[00:00&lt;00:00,â€‡â€‡9.43it/s]"
     }
    },
    "22ea45365d21439fb5069974bbe69711": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "23a71f8847e647daba35e495706fc846": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_22ea45365d21439fb5069974bbe69711",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_bd087d0aa3214c5dbecc9b0bd4d976df",
      "value": "Resolvingâ€‡dataâ€‡files:â€‡100%"
     }
    },
    "273bf76f74bc4fb492ccb67d9e202f7b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "284192f01a924f87afd8b5087ca9af6c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2c5564fb033346afbe7692a24a52b302": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "31a203cdd2f54cda8a05214844888156": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "320c09781518483e82defa86c28316d1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "32cff795f8bc490dbf63ed130e1f581f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "33fb10908c23457aa4796626102fc8c5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "341dca5ac74348dd9b5a347e38fa0b40": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3564e3cf0fe84281838d84525794e735": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_912164947c5847908424f3e60c5adb64",
       "IPY_MODEL_7517ce80636040e29665a9353afab183",
       "IPY_MODEL_e14b9d980a1a41fb9e81385cb0f73d3a"
      ],
      "layout": "IPY_MODEL_ada78aafba3f47ab8eb45cf3c83a6805"
     }
    },
    "37803098ceed4528bb690ebee028c840": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "39d3b72ab6214bcf9b0bb6b6294e957c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3a97281be4c1433aa3abe6c25b7113e2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4e19e78059b842a5832ccae2f765a30c",
       "IPY_MODEL_1a72b512e1374e67a858edf2844fc157",
       "IPY_MODEL_c9cfd66b68a1437d946c83163fa877df"
      ],
      "layout": "IPY_MODEL_cccd970273ae43d2a6e60ac421bdc882"
     }
    },
    "3f7afd4bd28842cbb73e62c155667030": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9a5fd3a68fd1445f92bea51a7fec3e6b",
      "max": 18,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_37803098ceed4528bb690ebee028c840",
      "value": 18
     }
    },
    "44f189b81bbd48ca8cb146ead641d2b5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e903140c8c794c48b231924d3975b7a6",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_7e74d789c82747e0b5066a00b9e36c1d",
      "value": "â€‡100/100â€‡[00:00&lt;00:00,â€‡125.88â€‡examples/s]"
     }
    },
    "45b3259e3cac4de8bd19d12f07de2adb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "45c1d5b0df0e420a87f791dd4cf0e425": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4a0426a353ca41cba39d4dfeba925451": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4e19e78059b842a5832ccae2f765a30c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_32cff795f8bc490dbf63ed130e1f581f",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_4a0426a353ca41cba39d4dfeba925451",
      "value": "Resolvingâ€‡dataâ€‡files:â€‡100%"
     }
    },
    "4f68a26f64e844c7be21cc180eb6c1a2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_341dca5ac74348dd9b5a347e38fa0b40",
      "max": 18,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8ba6fd1bf16a4680b8a8c9c55ecf23e7",
      "value": 18
     }
    },
    "51a6d3c97480476e8c22d9ad670bdc47": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "53ee8f5e8b7d4076bdb0167baf2e5729": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "58b932a03b2c4aa4891d541f186244b9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5d1fbd3c62d94df7befdefc451221414": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8ad6abb48f38469f9d399eea8f5e5b70",
       "IPY_MODEL_6cea0da24cf54811a43168c606759bab",
       "IPY_MODEL_eb8c88f5c06c49fe9099371b3cf112ae"
      ],
      "layout": "IPY_MODEL_89a1354722e640758978befc06ed4a78"
     }
    },
    "64539b4212fe4d989976f56369bb746b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "67b9a3505ae644dbb3c4fc14781a2731": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_53ee8f5e8b7d4076bdb0167baf2e5729",
      "max": 100,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d70fd9035f9b4d82892fae34c28c46d5",
      "value": 100
     }
    },
    "696e82ec6a174974a90d5abc7c101ee7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6cea0da24cf54811a43168c606759bab": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dade882aca304a31b693a2c58807d825",
      "max": 18,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_02fc530028ea4d538b7f6b48463ae700",
      "value": 18
     }
    },
    "72eca1e2871b458abd3383d9711215a2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_058b2b9959b84b6f9f5d3862ef53d029",
       "IPY_MODEL_85d4879bd7d64766905db34cef052fed",
       "IPY_MODEL_44f189b81bbd48ca8cb146ead641d2b5"
      ],
      "layout": "IPY_MODEL_f89c5c949e984361bce7f97d86d2a2e5"
     }
    },
    "734b6d3e3406403293c4bc955a643528": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dc3b2edc3f5d480a93b57b15b4444608",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_7967d420aff1414e9fe53eb04c928eb4",
      "value": "Map:â€‡100%"
     }
    },
    "7517ce80636040e29665a9353afab183": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bb078c8c1f6a48359dc654d91ece684d",
      "max": 18,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9b9322336b564a409086955ebda07fc3",
      "value": 18
     }
    },
    "769b40273bab41af8eb66e494b613241": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dc85f5e365f4488fa185d0ae35fde806",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_51a6d3c97480476e8c22d9ad670bdc47",
      "value": "â€‡18/18â€‡[00:00&lt;00:00,â€‡1567.70it/s]"
     }
    },
    "7807f312425b4f4d9249aa1ac77d7461": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "793f49f397b54daab63194cee8d04256": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7967d420aff1414e9fe53eb04c928eb4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7e11cccce8be49008f8db3a0c3ea603d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7e74d789c82747e0b5066a00b9e36c1d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "82c6c2752a0746f3935e069c0f8811d6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "85d4879bd7d64766905db34cef052fed": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0058ed544fed4272848a891a68b9adc0",
      "max": 100,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_33fb10908c23457aa4796626102fc8c5",
      "value": 100
     }
    },
    "89a1354722e640758978befc06ed4a78": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8a195771bdc0462e8f9fbb60eb9141b1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8a8d3a006ee24c4393d7c2f2d040ce52": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8ad6abb48f38469f9d399eea8f5e5b70": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_39d3b72ab6214bcf9b0bb6b6294e957c",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_696e82ec6a174974a90d5abc7c101ee7",
      "value": "Resolvingâ€‡dataâ€‡files:â€‡100%"
     }
    },
    "8ba6fd1bf16a4680b8a8c9c55ecf23e7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8d153f070a8d4ad1b32996a9fd82beda": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8f88a5b04723482ea430679e504c65f9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "912164947c5847908424f3e60c5adb64": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ff108c92fb5547869ee545cf9a094b07",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_2c5564fb033346afbe7692a24a52b302",
      "value": "Loadingâ€‡datasetâ€‡shards:â€‡100%"
     }
    },
    "9344b22940c64654a82bb2ce06530e30": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_793f49f397b54daab63194cee8d04256",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_fa79cfa23f3a430dab69a59d93383cd0",
      "value": "Resolvingâ€‡dataâ€‡files:â€‡100%"
     }
    },
    "963c0aa5620b4ea8b5a903894646121c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9a5fd3a68fd1445f92bea51a7fec3e6b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9b9322336b564a409086955ebda07fc3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "9bceb9eddb2147c1abbf3391c70e6784": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9ed49f1a099846a3a65cd6608bafb0e4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "9f91f7ce62e243f59d72e5ba36f97b8f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_af0233735d744b7e838f50f52c9d6cbe",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_8a8d3a006ee24c4393d7c2f2d040ce52",
      "value": "Loadingâ€‡datasetâ€‡shards:â€‡100%"
     }
    },
    "a419499622cd4374937423a79677298f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b93514308ae44afbb1a0511f5f9c6ddf",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_58b932a03b2c4aa4891d541f186244b9",
      "value": "â€‡18/18â€‡[00:00&lt;00:00,â€‡1458.49it/s]"
     }
    },
    "ada78aafba3f47ab8eb45cf3c83a6805": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "af0096de28414303ba5324f4087cd92e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "af0233735d744b7e838f50f52c9d6cbe": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b7e7896aeac74b6eae27de0677100e57": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b8b277831f1a45109b3a4a3565fbdb9d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9f91f7ce62e243f59d72e5ba36f97b8f",
       "IPY_MODEL_1634ba52355b4681a913039666926f85",
       "IPY_MODEL_217ca5cd404d4756a399fba3aa4fbc15"
      ],
      "layout": "IPY_MODEL_bc6d92cb8837428bb7038d75e6af604e"
     }
    },
    "b93514308ae44afbb1a0511f5f9c6ddf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bb078c8c1f6a48359dc654d91ece684d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bb1156b7d349440d9cc8a2f0328465a7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_23a71f8847e647daba35e495706fc846",
       "IPY_MODEL_3f7afd4bd28842cbb73e62c155667030",
       "IPY_MODEL_a419499622cd4374937423a79677298f"
      ],
      "layout": "IPY_MODEL_64539b4212fe4d989976f56369bb746b"
     }
    },
    "bc6d92cb8837428bb7038d75e6af604e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bd087d0aa3214c5dbecc9b0bd4d976df": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "be6162f66e594d3ebd8c53ebab3bbfa6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_963c0aa5620b4ea8b5a903894646121c",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_31a203cdd2f54cda8a05214844888156",
      "value": "â€‡100/100â€‡[00:00&lt;00:00,â€‡5440.44â€‡examples/s]"
     }
    },
    "c4d39c87c16c4961b942d896742ff7ce": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_af0096de28414303ba5324f4087cd92e",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_0f55ae30c2704632941cca4727c1c4f2",
      "value": "â€‡100/100â€‡[00:01&lt;00:00,â€‡113.55â€‡examples/s]"
     }
    },
    "c9cfd66b68a1437d946c83163fa877df": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_45b3259e3cac4de8bd19d12f07de2adb",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_b7e7896aeac74b6eae27de0677100e57",
      "value": "â€‡18/18â€‡[00:00&lt;00:00,â€‡â€‡1.32it/s]"
     }
    },
    "cccd970273ae43d2a6e60ac421bdc882": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d70fd9035f9b4d82892fae34c28c46d5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d8e7ea9552a84b8284b31d77090b54af": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "da5cd094aaae45f4a0ca051ad5babd78": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "dade882aca304a31b693a2c58807d825": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dc3b2edc3f5d480a93b57b15b4444608": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dc85f5e365f4488fa185d0ae35fde806": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e14b9d980a1a41fb9e81385cb0f73d3a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9bceb9eddb2147c1abbf3391c70e6784",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_8a195771bdc0462e8f9fbb60eb9141b1",
      "value": "â€‡18/18â€‡[00:35&lt;00:00,â€‡â€‡1.20it/s]"
     }
    },
    "e257e4a2bfdb48038102173d397ab2e4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_82c6c2752a0746f3935e069c0f8811d6",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_1850ab17bafd4a43b5ab5899d1875a40",
      "value": "Mapâ€‡(num_proc=2):â€‡100%"
     }
    },
    "e3bd7f85ce194cd4b697c2eb82038658": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_734b6d3e3406403293c4bc955a643528",
       "IPY_MODEL_0005f2d9fe1e4cc98ea58b0c2868b433",
       "IPY_MODEL_be6162f66e594d3ebd8c53ebab3bbfa6"
      ],
      "layout": "IPY_MODEL_7e11cccce8be49008f8db3a0c3ea603d"
     }
    },
    "e5880b946aae4b84a94226a5d6acaf45": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e903140c8c794c48b231924d3975b7a6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "eb8c88f5c06c49fe9099371b3cf112ae": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_00eea4b0c6e44c62900ea8e7d919efe9",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_fe17bedb5ef04d8b9e064fa1e0d75185",
      "value": "â€‡18/18â€‡[00:00&lt;00:00,â€‡â€‡1.42it/s]"
     }
    },
    "eff94d2d010e4b4f93a6dfcb61103a52": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f89c5c949e984361bce7f97d86d2a2e5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fa79cfa23f3a430dab69a59d93383cd0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fe17bedb5ef04d8b9e064fa1e0d75185": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ff108c92fb5547869ee545cf9a094b07": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ffa74977e7464cebb16d3cf8ee976d51": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e257e4a2bfdb48038102173d397ab2e4",
       "IPY_MODEL_67b9a3505ae644dbb3c4fc14781a2731",
       "IPY_MODEL_c4d39c87c16c4961b942d896742ff7ce"
      ],
      "layout": "IPY_MODEL_e5880b946aae4b84a94226a5d6acaf45"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
